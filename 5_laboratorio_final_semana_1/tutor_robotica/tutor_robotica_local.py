#!/usr/bin/env python3
"""
Tutor de Rob√≥tica Inteligente - Versi√≥n Local con Ollama
Script que act√∫a como tutor personalizado para ense√±ar rob√≥tica, Arduino, 
electr√≥nica, mecatr√≥nica y programaci√≥n a estudiantes de diferentes edades.

Esta versi√≥n utiliza Ollama con modelos locales en lugar de OpenAI para:
1. Adaptar el lenguaje seg√∫n el nivel educativo (preescolar, primaria, secundaria, preparatoria)
2. Explicar conceptos de rob√≥tica de manera apropiada para cada edad
3. Proporcionar ejemplos pr√°cticos y proyectos adaptados
4. Soportar m√∫ltiples idiomas para la ense√±anza
5. Funcionar completamente offline sin costos de API

REQUISITOS:
- Ollama instalado y ejecut√°ndose (ollama serve)
- Modelo descargado (ollama run gpt-oss:20b)
"""

# ============================================================================
# IMPORTACIONES NECESARIAS
# ============================================================================
import os                    # Para variables de entorno
import json                 # Para manejar respuestas JSON
import ollama               # Cliente de Ollama para modelos locales
from typing import Dict, List       # Para type hints

# ============================================================================
# CONFIGURACI√ìN INICIAL Y VALIDACI√ìN
# ============================================================================

# Configuraci√≥n del modelo local de Ollama
MODEL = 'gpt-oss:20b'   # Modelo local eficiente para tareas educativas
OLLAMA_HOST = 'http://127.0.0.1:11434'  # Servidor local de Ollama

def verificar_ollama():
    """
    Verifica que Ollama est√© ejecut√°ndose y el modelo est√© disponible.
    """
    try:
        # Intentar listar modelos disponibles
        models_response = ollama.list()
        
        # La respuesta de ollama.list() tiene una estructura diferente
        # Contiene un atributo 'models' que es una lista de objetos Model
        if hasattr(models_response, 'models') and models_response.models:
            model_names = [model.model for model in models_response.models]
            
            if MODEL in model_names:
                print(f"‚úì Modelo {MODEL} disponible en Ollama")
                return True
            else:
                print(f"‚ùå Modelo {MODEL} no encontrado. Modelos disponibles: {model_names}")
                print(f"üí° Ejecuta: ollama run {MODEL}")
                return False
        else:
            print("‚ùå No se encontraron modelos en Ollama")
            return False
            
    except Exception as e:
        print(f"‚ùå Error conectando con Ollama: {e}")
        print("üí° Aseg√∫rate de que Ollama est√© ejecut√°ndose: ollama serve")
        return False

# Verificar Ollama al importar
if not verificar_ollama():
    print("‚ö†Ô∏è Continuando sin verificaci√≥n de Ollama...")

# ============================================================================
# CONFIGURACI√ìN DE NIVELES EDUCATIVOS
# ============================================================================

NIVELES_EDUCATIVOS = {
    "preescolar": {
        "edad": "3-6 a√±os",
        "descripcion": "Nivel inicial con conceptos muy b√°sicos y juegos",
        "vocabulario": "simple",
        "ejemplos": "cotidianos"
    },
    "primaria": {
        "edad": "6-12 a√±os", 
        "descripcion": "Conceptos b√°sicos con experimentos sencillos",
        "vocabulario": "b√°sico",
        "ejemplos": "pr√°cticos"
    },
    "secundaria": {
        "edad": "12-15 a√±os",
        "descripcion": "Conceptos intermedios con proyectos estructurados", 
        "vocabulario": "t√©cnico b√°sico",
        "ejemplos": "proyectos"
    },
    "preparatoria": {
        "edad": "15-18 a√±os",
        "descripcion": "Conceptos avanzados con aplicaciones reales",
        "vocabulario": "t√©cnico avanzado", 
        "ejemplos": "profesionales"
    }
}

TEMAS_ROBOTICA = [
    "arduino", "electronica", "mecatronica", "programacion", 
    "sensores", "actuadores", "motores", "circuitos", "codigo",
    "proyectos", "robotica_basica", "automatizacion"
]

# ============================================================================
# PROMPTS MULTI-SHOT PARA DIFERENTES NIVELES
# ============================================================================

def cargar_prompt_desde_archivo(nivel: str) -> str:
    """
    Carga el prompt multi-shot desde un archivo externo.
    
    Args:
        nivel (str): Nivel educativo (preescolar, primaria, secundaria, preparatoria)
        
    Returns:
        str: Contenido del archivo de prompt
    """
    try:
        archivo_prompt = f"prompts/{nivel}.txt"
        with open(archivo_prompt, 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Archivo de prompt no encontrado: {archivo_prompt}")
        return "No hay ejemplos disponibles para este nivel."
    except Exception as e:
        print(f"‚ùå Error al cargar prompt: {e}")
        return "Error al cargar ejemplos."

def get_system_prompt_multishot(nivel: str, language: str = "Espa√±ol") -> str:
    """
    Genera el prompt del sistema con ejemplos multi-shot para cada nivel educativo.
    
    Args:
        nivel (str): Nivel educativo (preescolar, primaria, secundaria, preparatoria)
        language (str): Idioma para las respuestas
        
    Returns:
        str: Prompt del sistema con ejemplos multi-shot
    """
    
    base_prompt = f"""Eres un tutor experto en rob√≥tica, Arduino, electr√≥nica, mecatr√≥nica y programaci√≥n. 
Tu especialidad es adaptar tu ense√±anza al nivel educativo del estudiante.

NIVEL ACTUAL: {nivel.upper()} ({NIVELES_EDUCATIVOS[nivel]['edad']})
CARACTER√çSTICAS DEL NIVEL:
- {NIVELES_EDUCATIVOS[nivel]['descripcion']}
- Vocabulario: {NIVELES_EDUCATIVOS[nivel]['vocabulario']}
- Tipo de ejemplos: {NIVELES_EDUCATIVOS[nivel]['ejemplos']}

INSTRUCCIONES GENERALES:
1. Adapta tu lenguaje al nivel de edad especificado
2. Usa analog√≠as y ejemplos apropiados para la edad
3. Incluye emojis para hacer m√°s atractiva la explicaci√≥n
4. Proporciona ejemplos pr√°cticos cuando sea posible
5. Fomenta la curiosidad y el aprendizaje activo
6. Responde en formato Markdown para mejor legibilidad

EJEMPLOS DE RESPUESTAS MULTI-SHOT PARA NIVEL {nivel.upper()}:"""

    # Cargar ejemplos desde archivo externo
    ejemplos = cargar_prompt_desde_archivo(nivel)
    
    # Agregar configuraci√≥n de idioma
    language_config = f"""

CONFIGURACI√ìN DE IDIOMA:
- TODAS las respuestas deben generarse en {language}
- Mant√©n el formato Markdown y los emojis
- Adapta las expresiones culturalmente al idioma seleccionado
- Los t√©rminos t√©cnicos pueden mantenerse en ingl√©s si es est√°ndar internacional
"""

    return base_prompt + ejemplos + language_config

# ============================================================================
# CLASE PRINCIPAL DEL TUTOR LOCAL
# ============================================================================

class TutorRoboticaLocal:
    """
    Clase principal del tutor de rob√≥tica que maneja la interacci√≥n 
    con el estudiante y adapta las respuestas seg√∫n el nivel educativo.
    Utiliza Ollama para funcionar completamente offline.
    """
    
    def __init__(self, nivel: str = "primaria", language: str = "Espa√±ol"):
        """
        Inicializa el tutor con un nivel educativo y idioma espec√≠fico.
        
        Args:
            nivel (str): Nivel educativo del estudiante
            language (str): Idioma para las respuestas
        """
        if nivel not in NIVELES_EDUCATIVOS:
            raise ValueError(f"Nivel '{nivel}' no v√°lido. Opciones: {list(NIVELES_EDUCATIVOS.keys())}")
        
        self.nivel = nivel
        self.language = language
        self.system_prompt = get_system_prompt_multishot(nivel, language)
        
        print(f"ü§ñ Tutor de Rob√≥tica Local inicializado")
        print(f"üìö Nivel: {nivel.title()} ({NIVELES_EDUCATIVOS[nivel]['edad']})")
        print(f"üåç Idioma: {language}")
        print(f"üîß Modelo: {MODEL} (Local)")
        print(f"‚ú® {NIVELES_EDUCATIVOS[nivel]['descripcion']}")
    
    def cambiar_nivel(self, nuevo_nivel: str):
        """
        Cambia el nivel educativo del tutor.
        
        Args:
            nuevo_nivel (str): Nuevo nivel educativo
        """
        if nuevo_nivel not in NIVELES_EDUCATIVOS:
            print(f"‚ùå Nivel '{nuevo_nivel}' no v√°lido. Opciones: {list(NIVELES_EDUCATIVOS.keys())}")
            return
        
        self.nivel = nuevo_nivel
        self.system_prompt = get_system_prompt_multishot(nuevo_nivel, self.language)
        print(f"üìö Nivel cambiado a: {nuevo_nivel.title()} ({NIVELES_EDUCATIVOS[nuevo_nivel]['edad']})")
    
    def cambiar_idioma(self, nuevo_idioma: str):
        """
        Cambia el idioma de las respuestas del tutor.
        
        Args:
            nuevo_idioma (str): Nuevo idioma para las respuestas
        """
        self.language = nuevo_idioma
        self.system_prompt = get_system_prompt_multishot(self.nivel, nuevo_idioma)
        print(f"üåç Idioma cambiado a: {nuevo_idioma}")
    
    def responder_pregunta(self, pregunta: str, tema: str = "general") -> str:
        """
        Responde una pregunta del estudiante adaptada a su nivel usando Ollama.
        
        Args:
            pregunta (str): Pregunta del estudiante
            tema (str): Tema espec√≠fico (opcional)
            
        Returns:
            str: Respuesta del tutor adaptada al nivel
        """
        try:
            # Crear el prompt del usuario con contexto del tema
            user_prompt = f"""
TEMA: {tema.upper() if tema != "general" else "ROB√ìTICA GENERAL"}
PREGUNTA DEL ESTUDIANTE: {pregunta}

Por favor, responde esta pregunta adaptando tu explicaci√≥n al nivel {self.nivel} 
({NIVELES_EDUCATIVOS[self.nivel]['edad']}). Usa el estilo y formato de los ejemplos 
multi-shot proporcionados en el prompt del sistema.
"""
            
            # Preparar mensajes para Ollama
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # Mostrar encabezado
            print(f"\nü§ñ Tutor de Rob√≥tica Local - Nivel {self.nivel.title()}")
            print("=" * 50)
            print("üîÑ Generando respuesta con modelo local...")
            
            # Realizar llamada a Ollama
            response = ollama.chat(
                model=MODEL,
                messages=messages
            )
            
            # Obtener y mostrar respuesta
            content = response['message']['content']
            print(content)
            print("\n" + "=" * 50)
            return content
            
        except Exception as e:
            error_msg = f"‚ùå Error al generar respuesta con Ollama: {e}"
            print(error_msg)
            print("üí° Verifica que Ollama est√© ejecut√°ndose: ollama serve")
            print(f"üí° Verifica que el modelo est√© disponible: ollama run {MODEL}")
            return error_msg

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

def mostrar_menu():
    """Muestra el men√∫ principal del tutor."""
    print("\nü§ñ TUTOR DE ROB√ìTICA LOCAL - MEN√ö PRINCIPAL")
    print("=" * 45)
    print("1. üí¨ Hacer una pregunta")
    print("2. üìö Cambiar nivel educativo")
    print("3. üåç Cambiar idioma")
    print("4. ‚ÑπÔ∏è  Mostrar informaci√≥n actual")
    print("5. üìñ Mostrar temas disponibles")
    print("6. üîß Verificar estado de Ollama")
    print("7. üö™ Salir")
    print("=" * 45)

def mostrar_niveles():
    """Muestra los niveles educativos disponibles."""
    print("\nüìö NIVELES EDUCATIVOS DISPONIBLES:")
    print("-" * 35)
    for nivel, info in NIVELES_EDUCATIVOS.items():
        print(f"‚Ä¢ {nivel.title()}: {info['edad']} - {info['descripcion']}")

def mostrar_temas():
    """Muestra los temas de rob√≥tica disponibles."""
    print("\nüîß TEMAS DE ROB√ìTICA DISPONIBLES:")
    print("-" * 35)
    temas_formateados = [
        "Arduino", "Electr√≥nica", "Mecatr√≥nica", "Programaci√≥n",
        "Sensores", "Actuadores", "Motores", "Circuitos", 
        "C√≥digo", "Proyectos", "Rob√≥tica B√°sica", "Automatizaci√≥n"
    ]
    for i, tema in enumerate(temas_formateados, 1):
        print(f"{i:2d}. {tema}")

def mostrar_ejemplos_preguntas(nivel: str):
    """Muestra ejemplos de preguntas seg√∫n el nivel."""
    ejemplos = {
        "preescolar": [
            "¬øQu√© es un robot?",
            "¬øC√≥mo se enciende un LED?",
            "¬øPor qu√© los robots se mueven?"
        ],
        "primaria": [
            "¬øC√≥mo funciona Arduino?",
            "¬øQu√© son los sensores?",
            "¬øC√≥mo hago que un LED parpadee?"
        ],
        "secundaria": [
            "¬øC√≥mo programo un motor con Arduino?",
            "¬øC√≥mo calculo resistencias para LEDs?",
            "¬øQu√© es PWM y c√≥mo se usa?"
        ],
        "preparatoria": [
            "¬øC√≥mo implemento comunicaci√≥n I2C?",
            "¬øQu√© es un controlador PID?",
            "¬øC√≥mo dise√±o un sistema de control autom√°tico?"
        ]
    }
    
    print(f"\nüí° EJEMPLOS DE PREGUNTAS PARA {nivel.upper()}:")
    print("-" * 40)
    for pregunta in ejemplos[nivel]:
        print(f"‚Ä¢ {pregunta}")

def verificar_estado_ollama():
    """Verifica y muestra el estado de Ollama."""
    print("\nüîß VERIFICANDO ESTADO DE OLLAMA")
    print("-" * 30)
    
    try:
        # Verificar conexi√≥n
        models_response = ollama.list()
        print("‚úì Ollama est√° ejecut√°ndose correctamente")
        
        # Verificar si la respuesta tiene modelos
        if hasattr(models_response, 'models') and models_response.models:
            # Mostrar modelos disponibles
            print(f"\nüì¶ Modelos disponibles:")
            for model in models_response.models:
                model_name = model.model
                status = "‚úì ACTIVO" if model_name == MODEL else "‚óã Disponible"
                print(f"  {status} {model_name}")
            
            # Verificar modelo espec√≠fico
            model_names = [model.model for model in models_response.models]
            if MODEL in model_names:
                print(f"\n‚úì Modelo {MODEL} est√° listo para usar")
            else:
                print(f"\n‚ùå Modelo {MODEL} no encontrado")
                print(f"üí° Ejecuta: ollama run {MODEL}")
        else:
            print("‚ùå No se encontraron modelos en Ollama")
            
    except Exception as e:
        print(f"‚ùå Error conectando con Ollama: {e}")
        print("üí° Soluciones:")
        print("  1. Ejecuta: ollama serve")
        print("  2. Verifica que Ollama est√© instalado")
        print("  3. Reinicia el servicio de Ollama")

# ============================================================================
# FUNCI√ìN PRINCIPAL INTERACTIVA
# ============================================================================

def main():
    """
    Funci√≥n principal que maneja la interfaz interactiva del tutor local.
    """
    print("ü§ñ TUTOR DE ROB√ìTICA LOCAL CON OLLAMA")
    print("=" * 40)
    print("¬°Bienvenido al tutor personalizado de rob√≥tica!")
    print("Funciona completamente offline con modelos locales üîß‚ú®")
    
    # Verificar Ollama antes de continuar
    if not verificar_ollama():
        print("\n‚ö†Ô∏è Ollama no est√° disponible. El tutor puede no funcionar correctamente.")
        continuar = input("¬øDeseas continuar de todos modos? (s/n): ").lower().strip()
        if continuar != 's':
            print("üëã ¬°Configura Ollama y vuelve pronto!")
            return
    
    # Configuraci√≥n inicial
    print("\nüîß CONFIGURACI√ìN INICIAL")
    print("-" * 25)
    
    # Seleccionar nivel
    mostrar_niveles()
    while True:
        nivel = input("\nüìö Selecciona tu nivel educativo: ").lower().strip()
        if nivel in NIVELES_EDUCATIVOS:
            break
        print("‚ùå Nivel no v√°lido. Intenta de nuevo.")
    
    # Seleccionar idioma
    idiomas_disponibles = ["Espa√±ol", "English", "Fran√ßais", "Deutsch", "Italiano", "Portugu√™s"]
    print(f"\nüåç Idiomas disponibles: {', '.join(idiomas_disponibles)}")
    idioma = input("üåç Selecciona el idioma (por defecto Espa√±ol): ").strip()
    if not idioma:
        idioma = "Espa√±ol"
    
    # Inicializar tutor local
    tutor = TutorRoboticaLocal(nivel, idioma)
    
    # Mostrar ejemplos de preguntas
    mostrar_ejemplos_preguntas(nivel)
    
    # Bucle principal
    while True:
        mostrar_menu()
        opcion = input("\nüéØ Selecciona una opci√≥n (1-7): ").strip()
        
        if opcion == "1":
            # Hacer pregunta
            print("\nüí¨ HACER UNA PREGUNTA")
            print("-" * 20)
            mostrar_temas()
            tema = input("\nüîß Tema (opcional, presiona Enter para general): ").strip()
            if not tema:
                tema = "general"
            
            pregunta = input("‚ùì Tu pregunta: ").strip()
            if pregunta:
                tutor.responder_pregunta(pregunta, tema)
            else:
                print("‚ùå Por favor, escribe una pregunta.")
        
        elif opcion == "2":
            # Cambiar nivel
            print("\nüìö CAMBIAR NIVEL EDUCATIVO")
            print("-" * 25)
            mostrar_niveles()
            nuevo_nivel = input("üìö Nuevo nivel: ").lower().strip()
            tutor.cambiar_nivel(nuevo_nivel)
            if nuevo_nivel in NIVELES_EDUCATIVOS:
                mostrar_ejemplos_preguntas(nuevo_nivel)
        
        elif opcion == "3":
            # Cambiar idioma
            print("\nüåç CAMBIAR IDIOMA")
            print("-" * 15)
            print(f"Idiomas disponibles: {', '.join(idiomas_disponibles)}")
            nuevo_idioma = input("üåç Nuevo idioma: ").strip()
            if nuevo_idioma:
                tutor.cambiar_idioma(nuevo_idioma)
        
        elif opcion == "4":
            # Mostrar informaci√≥n actual
            print(f"\nüìä CONFIGURACI√ìN ACTUAL")
            print("-" * 25)
            print(f"üìö Nivel: {tutor.nivel.title()} ({NIVELES_EDUCATIVOS[tutor.nivel]['edad']})")
            print(f"üåç Idioma: {tutor.language}")
            print(f"üîß Modelo: {MODEL} (Local)")
            print(f"‚ú® Descripci√≥n: {NIVELES_EDUCATIVOS[tutor.nivel]['descripcion']}")
        
        elif opcion == "5":
            # Mostrar temas
            mostrar_temas()
            mostrar_ejemplos_preguntas(tutor.nivel)
        
        elif opcion == "6":
            # Verificar Ollama
            verificar_estado_ollama()
        
        elif opcion == "7":
            # Salir
            print("\nüëã ¬°Gracias por usar el Tutor de Rob√≥tica Local!")
            print("¬°Sigue aprendiendo y creando proyectos incre√≠bles! üöÄ‚ú®")
            break
        
        else:
            print("‚ùå Opci√≥n no v√°lida. Selecciona un n√∫mero del 1 al 7.")

# ============================================================================
# FUNCI√ìN PARA USO PROGRAM√ÅTICO
# ============================================================================

def crear_tutor_local_personalizado(nivel: str = "primaria", idioma: str = "Espa√±ol") -> TutorRoboticaLocal:
    """
    Funci√≥n auxiliar para crear un tutor local personalizado desde otros scripts.
    
    Args:
        nivel (str): Nivel educativo
        idioma (str): Idioma para las respuestas
        
    Returns:
        TutorRoboticaLocal: Instancia del tutor local configurada
    """
    return TutorRoboticaLocal(nivel, idioma)

# ============================================================================
# PUNTO DE ENTRADA DEL PROGRAMA
# ============================================================================

if __name__ == "__main__":
    """
    Punto de entrada del script.
    
    Ejecuta la interfaz interactiva del tutor local cuando el script
    se ejecuta directamente.
    """
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã ¬°Hasta luego! Gracias por usar el Tutor de Rob√≥tica Local ü§ñ‚ú®")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        print("Por favor, verifica tu configuraci√≥n de Ollama y vuelve a intentar.")
        print("üí° Comandos √∫tiles:")
        print("  - ollama serve")
        print(f"  - ollama run {MODEL}")