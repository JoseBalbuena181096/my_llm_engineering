"""
Asistente de IA para Aerol√≠nea con Herramientas (Tools)
=====================================================

Este script implementa un asistente de atenci√≥n al cliente para una aerol√≠nea ficticia 
llamada FlightAI. El asistente utiliza las herramientas (tools) de OpenAI para poder 
consultar precios de billetes de avi√≥n de forma din√°mica.

Caracter√≠sticas principales:
- Interfaz de chat web usando Gradio
- Integraci√≥n con OpenAI GPT-4o-mini
- Uso de herramientas para consultar precios de billetes
- Respuestas breves y corteses

Autor: Basado en el notebook day4.ipynb
"""

# ============================================================================
# IMPORTACIONES
# ============================================================================

import os          # Para acceder a variables de entorno
import json        # Para manejar datos JSON en las herramientas
from dotenv import load_dotenv  # Para cargar variables de entorno desde .env
from openai import OpenAI       # Cliente de OpenAI
import gradio as gr             # Para crear la interfaz web

# ============================================================================
# CONFIGURACI√ìN E INICIALIZACI√ìN
# ============================================================================

# Cargar variables de entorno desde el archivo .env
load_dotenv()

# Verificar que la API key de OpenAI est√© configurada
openai_api_key = os.getenv('OPENAI_API_KEY')
if openai_api_key:
    print(f"OpenAI API Key exists and begins {openai_api_key[:8]}")
else:
    print("OpenAI API Key Sin Configurar")
    exit(1)  # Salir si no hay API key
    
# Configuraci√≥n del modelo a utilizar
MODEL = "gpt-4o-mini"

# Inicializar el cliente de OpenAI
openai = OpenAI()

# ============================================================================
# CONFIGURACI√ìN DEL ASISTENTE
# ============================================================================

# Mensaje del sistema que define el comportamiento del asistente
# Este mensaje le dice al LLM c√≥mo debe comportarse y responder
system_message = "Eres un asistente √∫til para una aerol√≠nea llamada FlightAI. "
system_message += "Da respuestas breves y corteses, de no m√°s de una oraci√≥n. "
system_message += "Se siempre preciso. Si no sabes la respuesta, dilo."

# ============================================================================
# BASE DE DATOS DE PRECIOS (SIMULADA)
# ============================================================================

# Diccionario que simula una base de datos de precios de billetes
# En un sistema real, esto vendr√≠a de una base de datos o API externa
ticket_prices = {
    "londres": "799‚Ç¨", 
    "par√≠s": "899‚Ç¨", 
    "tokyo": "1400‚Ç¨", 
    "berl√≠n": "499‚Ç¨"
}

# ============================================================================
# FUNCIONES DE HERRAMIENTAS (TOOLS)
# ============================================================================

def get_ticket_price(destination_city):
    """
    Funci√≥n que consulta el precio de un billete a una ciudad espec√≠fica.
    
    Esta funci√≥n ser√° llamada autom√°ticamente por el LLM cuando necesite
    consultar precios de billetes.
    
    Args:
        destination_city (str): Nombre de la ciudad de destino
        
    Returns:
        str: Precio del billete o "Unknown" si no se encuentra la ciudad
    """
    print(f"Se solicit√≥ la herramienta get_ticket_price para {destination_city}")
    
    # Convertir a min√∫sculas para hacer la b√∫squeda case-insensitive
    city = destination_city.lower()
    
    # Buscar el precio en nuestro diccionario
    return ticket_prices.get(city, "Unknown")

# ============================================================================
# DEFINICI√ìN DE HERRAMIENTAS PARA OPENAI
# ============================================================================

# Estructura JSON que describe nuestra funci√≥n para que OpenAI la entienda
# Esta es la especificaci√≥n que le dice al LLM:
# - Qu√© hace la funci√≥n
# - Qu√© par√°metros necesita
# - Cu√°ndo debe usarla
price_function = {
    "name": "get_ticket_price",
    "description": "Obt√©n el precio de un billete de ida y vuelta a la ciudad de destino. Ll√°malo siempre que necesites saber el precio del billete, por ejemplo, cuando un cliente pregunte '¬øCu√°nto cuesta un billete a esta ciudad?'",
    "parameters": {
        "type": "object",
        "properties": {
            "destination_city": {
                "type": "string",
                "description": "La ciudad a la que el cliente desea viajar",
            },
        },
        "required": ["destination_city"],  # Par√°metros obligatorios
        "additionalProperties": False      # No permitir par√°metros adicionales
    }
}

# Lista de herramientas disponibles para el LLM
# Cada herramienta debe tener el tipo "function" y la definici√≥n de la funci√≥n
tools = [{"type": "function", "function": price_function}]

# ============================================================================
# MANEJO DE LLAMADAS A HERRAMIENTAS
# ============================================================================

def handle_tool_call(message):
    """
    Procesa una llamada a herramienta solicitada por el LLM.
    
    Cuando el LLM decide que necesita usar una herramienta, nos env√≠a una
    solicitud con los par√°metros. Esta funci√≥n ejecuta la herramienta
    y devuelve el resultado en el formato que espera OpenAI.
    
    Args:
        message: Mensaje de OpenAI que contiene la solicitud de herramienta
        
    Returns:
        tuple: (respuesta_formateada, ciudad_consultada)
    """
    # Extraer la primera (y √∫nica en este caso) llamada a herramienta
    tool_call = message.tool_calls[0]
    
    # Parsear los argumentos JSON enviados por el LLM
    arguments = json.loads(tool_call.function.arguments)
    
    # Extraer la ciudad de los argumentos
    city = arguments.get('destination_city')
    
    # Ejecutar nuestra funci√≥n de herramienta
    price = get_ticket_price(city)
    
    # Formatear la respuesta en el formato que espera OpenAI
    response = {
        "role": "tool",                                                    # Rol: respuesta de herramienta
        "content": json.dumps({"destination_city": city, "price": price}), # Contenido en JSON
        "tool_call_id": message.tool_calls[0].id                          # ID de la llamada original
    }
    
    return response, city

# ============================================================================
# FUNCI√ìN PRINCIPAL DE CHAT
# ============================================================================

def chat(message, history):
    """
    Funci√≥n principal que maneja la conversaci√≥n con el usuario.
    
    Esta funci√≥n:
    1. Prepara los mensajes para enviar a OpenAI
    2. Hace la llamada inicial al LLM
    3. Si el LLM quiere usar una herramienta, la ejecuta
    4. Hace una segunda llamada al LLM con el resultado de la herramienta
    5. Devuelve la respuesta final al usuario
    
    Args:
        message (str): Mensaje actual del usuario
        history (list): Historial de la conversaci√≥n
        
    Returns:
        str: Respuesta del asistente
    """
    # Construir la lista de mensajes para OpenAI
    # Incluye: mensaje del sistema + historial + mensaje actual
    messages = [
        {"role": "system", "content": system_message}  # Instrucciones del sistema
    ] + history + [                                    # Historial de conversaci√≥n
        {"role": "user", "content": message}           # Mensaje actual del usuario
    ]
    
    # Primera llamada a OpenAI con las herramientas disponibles
    response = openai.chat.completions.create(
        model=MODEL, 
        messages=messages, 
        tools=tools  # Herramientas disponibles
    )

    # Verificar si el LLM quiere usar una herramienta
    if response.choices[0].finish_reason == "tool_calls":
        # El LLM quiere usar una herramienta
        
        # Obtener el mensaje con la solicitud de herramienta
        message = response.choices[0].message
        
        # Ejecutar la herramienta solicitada
        tool_response, city = handle_tool_call(message)
        
        # Agregar la solicitud de herramienta al historial
        messages.append(message)
        
        # Agregar la respuesta de la herramienta al historial
        messages.append(tool_response)
        
        # Segunda llamada a OpenAI con el resultado de la herramienta
        # Ahora el LLM puede usar esta informaci√≥n para responder al usuario
        response = openai.chat.completions.create(model=MODEL, messages=messages)
    
    # Devolver la respuesta final del asistente
    return response.choices[0].message.content

# ============================================================================
# PUNTO DE ENTRADA PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    """
    Punto de entrada principal del programa.
    
    Cuando se ejecuta el script directamente, se lanza la interfaz web de Gradio
    con nuestro asistente de aerol√≠nea.
    """
    print("üõ´ Iniciando Asistente de Aerol√≠nea FlightAI...")
    print("üìã Herramientas disponibles: Consulta de precios de billetes")
    print("üåê Lanzando interfaz web...")
    
    # Crear y lanzar la interfaz de chat usando Gradio
    # - fn=chat: Funci√≥n que maneja la conversaci√≥n
    # - type="messages": Formato de mensajes para el historial
    gr.ChatInterface(fn=chat, type="messages").launch()