#!/usr/bin/env python3
"""
Script para conversaci√≥n entre Claude y GPT como expertos en educaci√≥n y tecnolog√≠a
Tema: Soluciones al problema de desconexi√≥n entre educaci√≥n universitaria y mundo laboral en M√©xico
Enfoque: Uso de IA, tecnolog√≠a e internet para soluciones accesibles y de bajo costo
"""

import os
import openai
import anthropic
from dotenv import load_dotenv
import time

# Cargar variables de entorno
load_dotenv()

# Configurar APIs
openai.api_key = os.getenv("OPENAI_API_KEY")
claude = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

# Configuraci√≥n de modelos
GPT_MODEL = "gpt-4o-mini"
CLAUDE_MODEL = "claude-3-haiku-20240307"

# Personalidades de los expertos
GPT_SYSTEM = """Eres un experto en tecnolog√≠a educativa y transformaci√≥n digital con amplia experiencia en M√©xico. 
Tu enfoque es pragm√°tico y orientado a resultados. Te especializas en:
- Implementaci√≥n de tecnolog√≠as educativas de bajo costo
- Plataformas digitales para capacitaci√≥n laboral
- Soluciones de IA para democratizar el acceso a la educaci√≥n
- Modelos de negocio sostenibles para EdTech en econom√≠as emergentes

Siempre propones soluciones concretas, factibles y escalables. Consideras las limitaciones econ√≥micas 
de M√©xico y buscas maximizar el impacto con recursos limitados. Eres directo y pr√°ctico en tus propuestas."""

CLAUDE_SYSTEM = """Eres un experto en pol√≠ticas educativas y desarrollo social con profundo conocimiento del contexto mexicano.
Tu enfoque es hol√≠stico y considera los aspectos sociales, econ√≥micos y culturales. Te especializas en:
- An√°lisis de brechas entre educaci√≥n superior y mercado laboral
- Pol√≠ticas p√∫blicas para inclusi√≥n digital
- Programas de capacitaci√≥n para poblaciones vulnerables
- Ecosistemas de innovaci√≥n social y tecnol√≥gica

Eres reflexivo, emp√°tico y siempre consideras el impacto social de las soluciones tecnol√≥gicas. 
Buscas equilibrar la innovaci√≥n con la equidad y la sostenibilidad social."""

class ConversacionEducacionMexico:
    def __init__(self):
        # Mensaje inicial que establece el contexto del debate
        self.tema_inicial = """El problema: En M√©xico existe una gran desconexi√≥n entre lo que se ense√±a en las universidades 
        y las habilidades que demanda el mercado laboral actual. Muchos graduados no encuentran empleo en su √°rea, 
        mientras que las empresas no encuentran talento con las competencias necesarias. Adem√°s, la mayor√≠a de la 
        poblaci√≥n tiene recursos econ√≥micos limitados para acceder a capacitaci√≥n adicional o programas de reconversi√≥n laboral.
        
        ¬øC√≥mo podemos usar la inteligencia artificial, internet y tecnolog√≠a en general para crear soluciones 
        accesibles y de bajo costo que ayuden a cerrar esta brecha?"""
        
        self.gpt_messages = []
        self.claude_messages = []
        
    def call_gpt(self, turno):
        """Llama a GPT con el contexto de la conversaci√≥n"""
        messages = [{"role": "system", "content": GPT_SYSTEM}]
        
        if turno == 0:
            # Primer mensaje: presentar el problema
            messages.append({"role": "user", "content": f"Contexto del debate:\n{self.tema_inicial}\n\nComo experto en tecnolog√≠a educativa, ¬øcu√°l es tu an√°lisis inicial del problema y qu√© soluciones tecnol√≥gicas propones?"})
        else:
            # Construir historial de la conversaci√≥n
            messages.append({"role": "user", "content": f"Contexto del debate:\n{self.tema_inicial}"})
            
            for i in range(len(self.claude_messages)):
                if i < len(self.gpt_messages):
                    messages.append({"role": "assistant", "content": self.gpt_messages[i]})
                messages.append({"role": "user", "content": f"El experto en pol√≠ticas educativas responde: {self.claude_messages[i]}"})
            
            messages.append({"role": "user", "content": "Contin√∫a el debate con tu siguiente propuesta o respuesta a los puntos planteados."})
        
        try:
            completion = openai.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=400,
                temperature=0.7
            )
            return completion.choices[0].message.content
        except Exception as e:
            return f"Error en GPT: {str(e)}"
    
    def call_claude(self, turno):
        """Llama a Claude con el contexto de la conversaci√≥n"""
        messages = []
        
        if turno == 0:
            # Primer mensaje: responder al an√°lisis de GPT
            if self.gpt_messages:
                messages.append({"role": "user", "content": f"Contexto del debate:\n{self.tema_inicial}\n\nEl experto en tecnolog√≠a educativa dice: {self.gpt_messages[0]}\n\nComo experto en pol√≠ticas educativas, ¬øcu√°l es tu perspectiva sobre este an√°lisis y qu√© complementar√≠as o matizar√≠as?"})
        else:
            # Construir historial de la conversaci√≥n
            messages.append({"role": "user", "content": f"Contexto del debate:\n{self.tema_inicial}"})
            
            for i in range(len(self.gpt_messages)):
                messages.append({"role": "user", "content": f"Experto en tecnolog√≠a: {self.gpt_messages[i]}"})
                if i < len(self.claude_messages):
                    messages.append({"role": "assistant", "content": self.claude_messages[i]})
            
            messages.append({"role": "user", "content": "Contin√∫a el debate con tu siguiente an√°lisis o propuesta."})
        
        try:
            message = claude.messages.create(
                model=CLAUDE_MODEL,
                system=CLAUDE_SYSTEM,
                messages=messages,
                max_tokens=400
            )
            return message.content[0].text
        except Exception as e:
            return f"Error en Claude: {str(e)}"
    
    def ejecutar_debate(self, num_mensajes=10):
        """Ejecuta el debate entre los dos expertos"""
        print("=== DEBATE: EDUCACI√ìN UNIVERSITARIA Y MUNDO LABORAL EN M√âXICO ===\n")
        print("üöÄ GPT - Experto en Tecnolog√≠a Educativa (Enfoque Pragm√°tico)")
        print("üéì Claude - Experto en Pol√≠ticas Educativas (Enfoque Hol√≠stico)")
        print("\n" + "="*80 + "\n")
        
        print("üìã CONTEXTO DEL DEBATE:")
        print(self.tema_inicial)
        print("\n" + "="*80 + "\n")
        
        for turno in range(num_mensajes):
            print(f"--- INTERCAMBIO {turno + 1} ---\n")
            
            # GPT inicia o responde
            gpt_response = self.call_gpt(turno)
            print(f"üöÄ EXPERTO EN TECNOLOG√çA EDUCATIVA (GPT):\n{gpt_response}\n")
            self.gpt_messages.append(gpt_response)
            time.sleep(2)  # Pausa para evitar rate limits
            
            # Claude responde
            claude_response = self.call_claude(turno)
            print(f"üéì EXPERTO EN POL√çTICAS EDUCATIVAS (Claude):\n{claude_response}\n")
            self.claude_messages.append(claude_response)
            time.sleep(2)
            
            print("-" * 80 + "\n")
    
    def generar_resumen_final(self):
        """Genera un resumen final de las propuestas discutidas"""
        print("=== RESUMEN EJECUTIVO DE PROPUESTAS ===\n")
        
        # Llamar a GPT para generar resumen
        messages = [
            {"role": "system", "content": "Eres un analista experto que debe crear un resumen ejecutivo conciso de las principales propuestas discutidas en el debate sobre educaci√≥n y tecnolog√≠a en M√©xico."},
            {"role": "user", "content": f"Bas√°ndote en este debate completo, crea un resumen ejecutivo con las 5 propuestas m√°s viables y concretas que surgieron:\n\nDebate completo:\n{self._obtener_debate_completo()}"}
        ]
        
        try:
            completion = openai.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=500,
                temperature=0.3
            )
            resumen = completion.choices[0].message.content
            print(f"üìä RESUMEN EJECUTIVO:\n{resumen}\n")
            return resumen
        except Exception as e:
            print(f"Error generando resumen: {str(e)}")
            return ""
    
    def _obtener_debate_completo(self):
        """Obtiene el texto completo del debate"""
        debate_completo = ""
        max_len = max(len(self.gpt_messages), len(self.claude_messages))
        
        for i in range(max_len):
            if i < len(self.gpt_messages):
                debate_completo += f"GPT: {self.gpt_messages[i]}\n\n"
            if i < len(self.claude_messages):
                debate_completo += f"Claude: {self.claude_messages[i]}\n\n"
        
        return debate_completo
    
    def convertir_a_markdown(self):
        """Convierte el debate completo a formato Markdown usando GPT"""
        debate_texto = self._obtener_debate_completo()
        
        prompt_conversion = f"""Convierte el siguiente debate entre expertos a un formato Markdown profesional y bien estructurado.

INSTRUCCIONES:
- Usa encabezados apropiados (##, ###)
- Formatea las citas y propuestas con > (blockquotes)
- Usa listas con vi√±etas para las propuestas
- Resalta conceptos importantes con **negrita**
- Usa emojis apropiados para hacer m√°s visual
- Estructura el contenido de manera clara y profesional
- Mant√©n todo el contenido t√©cnico y las propuestas

CONTEXTO DEL DEBATE:
{self.tema_inicial}

DEBATE A CONVERTIR:
{debate_texto}

Genera un documento Markdown completo, profesional y bien estructurado."""

        try:
            completion = openai.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "Eres un experto en documentaci√≥n t√©cnica y formato Markdown. Creas documentos profesionales, bien estructurados y visualmente atractivos."},
                    {"role": "user", "content": prompt_conversion}
                ],
                max_tokens=2000,
                temperature=0.3
            )
            return completion.choices[0].message.content
        except Exception as e:
            print(f"Error convirtiendo a Markdown: {str(e)}")
            return None

    def guardar_debate(self, archivo_txt="debate_educacion_mexico.txt", archivo_md="debate_educacion_mexico.md"):
        """Guarda el debate completo en formato texto y Markdown"""
        
        # Guardar en formato texto original
        with open(archivo_txt, 'w', encoding='utf-8') as f:
            f.write("=== DEBATE: EDUCACI√ìN UNIVERSITARIA Y MUNDO LABORAL EN M√âXICO ===\n\n")
            f.write("PARTICIPANTES:\n")
            f.write("üöÄ GPT - Experto en Tecnolog√≠a Educativa (Enfoque Pragm√°tico)\n")
            f.write("üéì Claude - Experto en Pol√≠ticas Educativas (Enfoque Hol√≠stico)\n\n")
            
            f.write("CONTEXTO:\n")
            f.write(f"{self.tema_inicial}\n\n")
            f.write("="*80 + "\n\n")
            
            max_len = max(len(self.gpt_messages), len(self.claude_messages))
            
            for i in range(max_len):
                f.write(f"--- INTERCAMBIO {i + 1} ---\n\n")
                if i < len(self.gpt_messages):
                    f.write(f"üöÄ EXPERTO EN TECNOLOG√çA EDUCATIVA (GPT):\n{self.gpt_messages[i]}\n\n")
                if i < len(self.claude_messages):
                    f.write(f"üéì EXPERTO EN POL√çTICAS EDUCATIVAS (Claude):\n{self.claude_messages[i]}\n\n")
                f.write("-" * 80 + "\n\n")
            
            # Agregar resumen si existe
            resumen = self.generar_resumen_final()
            if resumen:
                f.write("=== RESUMEN EJECUTIVO ===\n\n")
                f.write(resumen)
        
        print(f"üíæ Debate en formato texto guardado en: {archivo_txt}")
        
        # Convertir y guardar en formato Markdown
        print("üîÑ Convirtiendo debate a formato Markdown...")
        markdown_content = self.convertir_a_markdown()
        
        if markdown_content:
            with open(archivo_md, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            print(f"üìù Debate en formato Markdown guardado en: {archivo_md}")
        else:
            print("‚ùå Error al convertir a Markdown")

def main():
    """Funci√≥n principal"""
    print("üá≤üáΩ Iniciando debate sobre educaci√≥n y tecnolog√≠a en M√©xico...\n")
    
    # Verificar que las API keys est√©n configuradas
    if not all([os.getenv("OPENAI_API_KEY"), os.getenv("ANTHROPIC_API_KEY")]):
        print("‚ùå Error: Faltan API keys. Aseg√∫rate de tener configuradas:")
        print("   - OPENAI_API_KEY")
        print("   - ANTHROPIC_API_KEY")
        return
    
    try:
        debate = ConversacionEducacionMexico()
        debate.ejecutar_debate(num_mensajes=10)  # 10 mensajes por modelo
        debate.guardar_debate()
        
        print("\nüéâ Debate completado exitosamente!")
        print("üìÑ Revisa los archivos generados:")
        print("   - debate_educacion_mexico.txt (formato texto)")
        print("   - debate_educacion_mexico.md (formato Markdown)")
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è Debate interrumpido por el usuario.")
    except Exception as e:
        print(f"\n‚ùå Error durante el debate: {str(e)}")

if __name__ == "__main__":
    main()